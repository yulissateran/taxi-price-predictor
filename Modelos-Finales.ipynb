{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final model Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the Parquet file\n",
    "parquet_file_path = 'C:\\\\Users\\\\jaime\\\\Documents\\\\GitHub\\\\taxi-price-predictor\\\\trans_data.parquet'\n",
    "\n",
    "# Load the Parquet file into a pandas DataFrame\n",
    "df = pd.read_parquet(parquet_file_path)\n",
    "df_time = pd.read_parquet(parquet_file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and standard deviation\n",
    "mean_fare = df['fare_amount'].mean()\n",
    "std_fare = df['fare_amount'].std()\n",
    "\n",
    "# Create a new column for the standardized fare amounts\n",
    "df['fare_amount_sigmas'] = (df['fare_amount'] - mean_fare) / std_fare\n",
    "\n",
    "# Filter out rows with 'fare_amount' beyond 3 standard deviations\n",
    "df = df[(df['fare_amount_sigmas'] < 3) & (df['fare_amount_sigmas'] > -3)]\n",
    "\n",
    "# Filter out rows with non-positive 'fare_amount'\n",
    "df = df[df['fare_amount'] > 0]\n",
    "\n",
    "# Drop the 'fare_amount_sigmas' column\n",
    "df.drop(\"fare_amount_sigmas\", inplace=True, axis=1)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify the changes\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that 'tpep_dropoff_datetime' and 'tpep_pickup_datetime' are in datetime format\n",
    "df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])\n",
    "df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "\n",
    "# Add the new 'duration_in_minutes' column to the DataFrame\n",
    "df[\"duration_in_minutes\"] = (df[\"tpep_dropoff_datetime\"] - df[\"tpep_pickup_datetime\"]).dt.total_seconds() / 60\n",
    "\n",
    "# Extract datetime components and replace original datetime columns\n",
    "df[\"pickup_year\"] = df[\"tpep_pickup_datetime\"].dt.year\n",
    "df[\"pickup_day\"] = df[\"tpep_pickup_datetime\"].dt.day\n",
    "df[\"pickup_day_of_week\"] = df[\"tpep_pickup_datetime\"].dt.dayofweek\n",
    "df[\"pickup_hour\"] = df[\"tpep_pickup_datetime\"].dt.hour\n",
    "df[\"pickup_minute\"] = df[\"tpep_pickup_datetime\"].dt.minute\n",
    "\n",
    "# Drop the original datetime columns\n",
    "df.drop(\"tpep_pickup_datetime\", inplace=True, axis=1)\n",
    "df.drop(\"tpep_dropoff_datetime\", inplace=True, axis=1)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify the changes\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Ensure that 'pickup_year' is extracted and present in the DataFrame\n",
    "if 'pickup_year' not in df.columns:\n",
    "    df['pickup_year'] = pd.to_datetime(df['tpep_pickup_datetime']).dt.year\n",
    "\n",
    "# Remove rows that are not from 2022\n",
    "df.loc[df[\"pickup_year\"] != 2022, \"pickup_year\"] = np.nan\n",
    "\n",
    "# Replace all rows with trip_distance > 60 because they are outliers\n",
    "df.loc[df[\"trip_distance\"] > 60, \"trip_distance\"] = np.nan\n",
    "\n",
    "# Remove all rows with RatecodeID > 6 because according to docs RatecodeID can only go from 1 to 6\n",
    "df.loc[df[\"RatecodeID\"] > 6, \"RatecodeID\"] = np.nan\n",
    "\n",
    "# Remove rows with PULocationID > 263 or DOLocationID > 263 because they don't add value to the model\n",
    "df.loc[df[\"PULocationID\"] > 263, \"PULocationID\"] = np.nan\n",
    "df.loc[df[\"DOLocationID\"] > 263, \"DOLocationID\"] = np.nan\n",
    "\n",
    "# Filter out rows where total_amount is 400 or more\n",
    "df = df[df['total_amount'] < 400]\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify the changes\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None values in the 'store_and_fwd_flag' column with 'N'\n",
    "df[\"store_and_fwd_flag\"].replace({None: \"N\"}, inplace=True)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify the changes\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copies of the DataFrame for training and testing\n",
    "X_train = df.copy()\n",
    "X_test = df.copy()\n",
    "\n",
    "# Assign target columns to y_train\n",
    "y_train_total_amount = X_train[\"total_amount\"]\n",
    "y_train_duration_in_minutes = X_train[\"duration_in_minutes\"]\n",
    "\n",
    "# Drop target columns from X_train\n",
    "X_train.drop([\"total_amount\", \"duration_in_minutes\"], inplace=True, axis=1)\n",
    "\n",
    "# Assign target columns to y_test\n",
    "y_test_total_amount = X_test[\"total_amount\"]\n",
    "y_test_duration_in_minutes = X_test[\"duration_in_minutes\"]\n",
    "\n",
    "# Drop target columns from X_test\n",
    "X_test.drop([\"total_amount\", \"duration_in_minutes\"], inplace=True, axis=1)\n",
    "\n",
    "# Output the results\n",
    "print(X_train.head())\n",
    "print(y_train_total_amount.head())\n",
    "print(y_train_duration_in_minutes.head())\n",
    "print(X_test.head())\n",
    "print(y_test_total_amount.head())\n",
    "print(y_test_duration_in_minutes.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to remove specified columns from a DataFrame\n",
    "def remove_columns_in_place(dfs, columns_to_remove):\n",
    "    for df in dfs:\n",
    "        columns_to_remove_existing = [col for col in columns_to_remove if col in df.columns]\n",
    "        df.drop(columns=columns_to_remove_existing, axis=1, inplace=True)\n",
    "\n",
    "# List of columns to remove\n",
    "columns_to_remove = ['improvement_surcharge', 'congestion_surcharge', 'VendorID', \n",
    "                     'passenger_count', 'RatecodeID', 'store_and_fwd_flag', 'extra', 'tip_amount', 'fare_amount']\n",
    "\n",
    "# Your DataFrames\n",
    "df_list = [X_train, X_test]\n",
    "\n",
    "# Remove columns from all DataFrames in place\n",
    "remove_columns_in_place(df_list, columns_to_remove)\n",
    "\n",
    "# Display the first few rows of the cleaned DataFrame to verify the changes\n",
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Example LightGBM training code\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pickle\n",
    "# Prepare data for LightGBM\n",
    "train_data = lgb.Dataset(X_train, label=y_train_total_amount)\n",
    "test_data = lgb.Dataset(X_test, label=y_test_total_amount, reference=train_data)\n",
    "\n",
    "# Set parameters for LightGBM\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "num_round = 100\n",
    "bst = lgb.train(params, train_data, num_round, valid_sets=[test_data])\n",
    "# Save the model to a pickle file\n",
    "with open('lgb_model.pickle', 'wb') as model_file:\n",
    "    pickle.dump(bst, model_file)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = bst.predict(X_test, num_iteration=bst.best_iteration)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test_total_amount, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "r2 = r2_score(y_test_total_amount, y_pred)\n",
    "print(f\"R-squared: {r2:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final model time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time = pd.read_parquet(parquet_file_path)\n",
    "\n",
    "df_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove specified columns from a DataFrame\n",
    "def remove_columns(df_time, columns_to_remove):\n",
    "  columns_to_remove_existing = [col for col in columns_to_remove if col in df_time.columns]\n",
    "  df_time.drop(columns=columns_to_remove_existing, axis=1, inplace=True)\n",
    "  return df_time\n",
    "\n",
    "# List of columns to remove\n",
    "columns_to_remove = ['improvement_surcharge', 'congestion_surcharge', 'VendorID', \n",
    "                     'passenger_count', 'RatecodeID', 'store_and_fwd_flag', 'extra', 'tip_amount', 'fare_amount', 'payment_type']\n",
    "\n",
    "# Remove columns from the DataFrame\n",
    "df_time = remove_columns(df_time.copy(), columns_to_remove)\n",
    "\n",
    "# Display the first few rows of the cleaned DataFrame to verify the changes\n",
    "print(df_time.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_average_speed(df_time, min_trip_duration=1):\n",
    "  # Parse datetime columns\n",
    "  df_time['tpep_pickup_datetime'] = pd.to_datetime(df_time['tpep_pickup_datetime'])\n",
    "  df_time['tpep_dropoff_datetime'] = pd.to_datetime(df_time['tpep_dropoff_datetime'])\n",
    "\n",
    "  # Calculate trip duration in minutes\n",
    "  df_time['trip_duration'] = (df_time['tpep_dropoff_datetime'] - df_time['tpep_pickup_datetime']) / pd.Timedelta(minutes=1)\n",
    "\n",
    "  # Handle zero trip durations (optional)\n",
    "  df_time.loc[df_time['trip_duration'] == 0, 'trip_duration'] = min_trip_duration\n",
    "\n",
    "  # Calculate average speed in miles per minute\n",
    "  average_speed = df_time['trip_distance'] / df_time['trip_duration']\n",
    "\n",
    "  # Add new columns (rounded to two decimals)\n",
    "  df_time['average_speed_mph'] = average_speed.round(2)  # Miles per minute\n",
    "  df_time['trip_duration'] = df_time['trip_duration'].round(2)\n",
    "\n",
    "  return df_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time = add_average_speed(df_time.copy())\n",
    "\n",
    "# Now df_time_modified will have the new column\n",
    "print(df_time.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_columns(df_time, columns_to_remove):\n",
    "  columns_to_remove_existing = [col for col in columns_to_remove if col in df_time.columns]\n",
    "  df_time.drop(columns=columns_to_remove_existing, axis=1, inplace=True)\n",
    "  return df_time\n",
    "\n",
    "# List of columns to remove\n",
    "columns_to_remove = ['tpep_dropoff_datetime']\n",
    "\n",
    "# Remove columns from the DataFrame\n",
    "df_time = remove_columns(df_time.copy(), columns_to_remove)\n",
    "\n",
    "# Display the first few rows of the cleaned DataFrame to verify the changes\n",
    "print(df_time.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copies of the DataFrame for training and testing\n",
    "X_train = df_time.copy()\n",
    "X_test = df_time.copy()\n",
    "\n",
    "# Assign target column to y_train\n",
    "y_train_duration = X_train[\"trip_duration\"]\n",
    "\n",
    "# Drop target column from X_train\n",
    "X_train.drop([\"trip_duration\"], inplace=True, axis=1)\n",
    "\n",
    "# Assign target column to y_test\n",
    "y_test_duration = X_test[\"trip_duration\"]\n",
    "\n",
    "# Drop target column from X_test\n",
    "X_test.drop([\"trip_duration\"], inplace=True, axis=1)\n",
    "\n",
    "# Output the results\n",
    "print(X_train.head())\n",
    "print(y_train_duration.head())\n",
    "print(X_test.head())\n",
    "print(y_test_duration.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "# Drop datetime columns from the feature set\n",
    "X = df_time.drop(columns=['trip_duration', 'tpep_pickup_datetime'])\n",
    "y = df_time['trip_duration']\n",
    "\n",
    "# Convert categorical columns to numeric using one-hot encoding\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Fill NaN values with the median of each column\n",
    "X.fillna(X.median(), inplace=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# LightGBM Regressor\n",
    "lgbm = lgb.LGBMRegressor(random_state=42)\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_pred_lgbm = lgbm.predict(X_test)\n",
    "r2_lgbm = r2_score(y_test, y_pred_lgbm)\n",
    "mse_lgbm = mean_squared_error(y_test, y_pred_lgbm)\n",
    "# Save the model\n",
    "with open('lightgbm_regressor_model.pkl', 'wb') as file:\n",
    "    pickle.dump(lgbm, file)\n",
    "\n",
    "# XGBoost Regressor\n",
    "xgbr = xgb.XGBRegressor(random_state=42)\n",
    "xgbr.fit(X_train, y_train)\n",
    "y_pred_xgbr = xgbr.predict(X_test)\n",
    "r2_xgbr = r2_score(y_test, y_pred_xgbr)\n",
    "mse_xgbr = mean_squared_error(y_test, y_pred_xgbr)\n",
    "# Save the model\n",
    "with open('xgboost_regressor_model.pkl', 'wb') as file:\n",
    "    pickle.dump(xgbr, file)\n",
    "\n",
    "\n",
    "# Print the results\n",
    "print(f\"LightGBM Regressor - R2: {r2_lgbm:.4f}, MSE: {mse_lgbm:.4f}\")\n",
    "print(f\"XGBoost Regressor - R2: {r2_xgbr:.4f}, MSE: {mse_xgbr:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved LightGBM Regressor model\n",
    "with open('lightgbm_regressor_model.pkl', 'rb') as file:\n",
    "    loaded_lgbm = pickle.load(file)\n",
    "\n",
    "# Make predictions with the loaded model\n",
    "loaded_lgbm_predictions = loaded_lgbm.predict(X_test)\n",
    "print(f\"Loaded LightGBM Regressor - R2: {r2_score(y_test, loaded_lgbm_predictions):.4f}, MSE: {mean_squared_error(y_test, loaded_lgbm_predictions):.4f}\")\n",
    "\n",
    "# Load the saved XGBoost Regressor model\n",
    "with open('xgboost_regressor_model.pkl', 'rb') as file:\n",
    "    loaded_xgbr = pickle.load(file)\n",
    "\n",
    "# Make predictions with the loaded model\n",
    "loaded_xgbr_predictions = loaded_xgbr.predict(X_test)\n",
    "print(f\"Loaded XGBoost Regressor - R2: {r2_score(y_test, loaded_xgbr_predictions):.4f}, MSE: {mean_squared_error(y_test, loaded_xgbr_predictions):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "df_time = df_time[['pickup_datetime', 'trip_distance', 'trip_duration', 'PULocationID']]\n",
    "\n",
    "df_time['pickup_datetime'] = pd.to_datetime(df_time['pickup_datetime'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
