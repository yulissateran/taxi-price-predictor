{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 1. Preprocessing"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 47,
         "metadata": {},
         "outputs": [],
         "source": [
            "from imp import reload\n",
            "from src import config, data_utilsf, preprocessing\n",
            "import pandas as pd"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Getting the data"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 48,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "columns Index(['PULocationID', 'DOLocationID', 'mta_tax', 'total_amount',\n",
                  "       'airport_fee', 'trip_duration', 'average_speed_mph',\n",
                  "       'duration_in_minutes', 'pickup_year', 'pickup_day',\n",
                  "       'pickup_day_of_week', 'pickup_hour', 'pickup_minute'],\n",
                  "      dtype='object')\n"
               ]
            },
            {
               "data": {
                  "text/plain": [
                     "Index(['PULocationID', 'DOLocationID', 'mta_tax', 'total_amount',\n",
                     "       'airport_fee', 'trip_duration', 'average_speed_mph',\n",
                     "       'duration_in_minutes', 'pickup_year', 'pickup_day',\n",
                     "       'pickup_day_of_week', 'pickup_hour', 'pickup_minute'],\n",
                     "      dtype='object')"
                  ]
               },
               "execution_count": 48,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "app_train, app_test = data_utilsf.get_datasets()\n",
            "app_train.columns"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Agregating columns"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [],
         "source": [
            "\n",
            "#reload(data_utils)\n",
            "#app_train =  data_utils.agregate_columns(app_train)\n",
            "#app_test =  data_utils.agregate_columns(app_test)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Split targets from dataset"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 49,
         "metadata": {},
         "outputs": [],
         "source": [
            "(\n",
            " X_train,\n",
            " y_train_total_amount,\n",
            " y_train_duration_in_minutes,\n",
            " X_test,\n",
            " y_test_total_amount,\n",
            " y_test_duration_in_minutes\n",
            ") = data_utilsf.get_feature_target(app_train, app_test)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Stract validation dataset"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 50,
         "metadata": {},
         "outputs": [],
         "source": [
            "(\n",
            "X_train,\n",
            "X_val,\n",
            "y_train_total_amount,\n",
            "y_val_total_amount,\n",
            "y_train_duration_in_minutes,\n",
            "y_val_duration_in_minutes\n",
            ") = data_utilsf.get_train_val_sets(X_train, y_train_total_amount, y_train_duration_in_minutes)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 51,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "(2819555, 11) (704889, 11) (3533786, 11)\n"
               ]
            }
         ],
         "source": [
            "print(X_train.shape, X_val.shape, X_test.shape)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Clear and encode datasets"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 52,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "<module 'src.preprocessing' from 'c:\\\\Users\\\\jaime\\\\Documents\\\\GitHub\\\\taxi-price-predictor\\\\src\\\\preprocessing.py'>"
                  ]
               },
               "execution_count": 52,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "reload(preprocessing)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 53,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Input train data shape:  (2819555, 11)\n",
                  "Input val data shape:  (704889, 11)\n",
                  "Input test data shape:  (3533786, 11) \n",
                  "\n"
               ]
            }
         ],
         "source": [
            "X_train, X_val, X_test = preprocessing.preprocess_data(X_train, X_val, X_test)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 54,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "(2819555, 11)\n",
                  "(3533786,)\n"
               ]
            }
         ],
         "source": [
            "print(X_train.shape)\n",
            "print(y_test_duration_in_minutes.shape)\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Models"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Linear Regression"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### Total amount prediction"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 55,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.105748 seconds.\n",
                  "You can set `force_col_wise=true` to remove the overhead.\n",
                  "[LightGBM] [Info] Total Bins 1066\n",
                  "[LightGBM] [Info] Number of data points in the train set: 2819555, number of used features: 10\n",
                  "[LightGBM] [Info] Start training from score 21.387523\n",
                  "Mean Squared Error on test set: 57.27152828625904\n",
                  "R-squared on test set: 0.82\n"
               ]
            }
         ],
         "source": [
            "import lightgbm as lgb\n",
            "from sklearn.model_selection import train_test_split\n",
            "from sklearn.metrics import mean_squared_error, r2_score\n",
            "import pickle\n",
            "\n",
            "\n",
            "\n",
            "# Prepare data for LightGBM\n",
            "train_data = lgb.Dataset(X_train, label=y_train_total_amount)\n",
            "val_data = lgb.Dataset(X_val, label=y_val_total_amount, reference=train_data)\n",
            "\n",
            "# Set parameters for LightGBM\n",
            "params = {\n",
            "    'objective': 'regression',\n",
            "    'metric': 'rmse',\n",
            "    'boosting_type': 'gbdt',\n",
            "    'num_leaves': 31,\n",
            "    'learning_rate': 0.05,\n",
            "    'feature_fraction': 0.9,\n",
            "}\n",
            "\n",
            "# Train the model with early stopping based on validation set\n",
            "num_round = 100\n",
            "bst = lgb.train(\n",
            "    params,\n",
            "    train_data,\n",
            "    num_round,\n",
            "    valid_sets=[val_data],\n",
            "    valid_names=[\"val\"],\n",
            "    \n",
            ")\n",
            "\n",
            "# Get the best iteration based on validation set performance\n",
            "best_iteration = bst.best_iteration\n",
            "\n",
            "# Save the model to a pickle file\n",
            "with open('Rate.pickle', 'wb') as model_file:\n",
            "    pickle.dump(bst, model_file)\n",
            "\n",
            "# Make predictions on the test set using the best iteration\n",
            "y_pred = bst.predict(X_test, num_iteration=best_iteration)\n",
            "\n",
            "# Evaluate the model on the test set\n",
            "mse = mean_squared_error(y_test_total_amount, y_pred)\n",
            "print(f'Mean Squared Error on test set: {mse}')\n",
            "r2 = r2_score(y_test_total_amount, y_pred)\n",
            "print(f\"R-squared on test set: {r2:.2f}\")\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 33,
         "metadata": {},
         "outputs": [
            {
               "ename": "AttributeError",
               "evalue": "module 'lightgbm' has no attribute 'feature_importance'",
               "output_type": "error",
               "traceback": [
                  "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
                  "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m importance \u001b[38;5;241m=\u001b[39m \u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_importance\u001b[49m(importance_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
                  "\u001b[1;31mAttributeError\u001b[0m: module 'lightgbm' has no attribute 'feature_importance'"
               ]
            }
         ],
         "source": [
            "importance = lgb.feature_importance(importance_type=\"gain\")\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 39,
         "metadata": {},
         "outputs": [
            {
               "ename": "AttributeError",
               "evalue": "'numpy.ndarray' object has no attribute 'columns'",
               "output_type": "error",
               "traceback": [
                  "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
                  "Cell \u001b[1;32mIn[39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\n",
                  "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
               ]
            }
         ],
         "source": [
            "X_train.columns"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 66,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066311 seconds.\n",
                  "You can set `force_row_wise=true` to remove the overhead.\n",
                  "And if memory is not enough, you can set `force_col_wise=true`.\n",
                  "[LightGBM] [Info] Total Bins 1066\n",
                  "[LightGBM] [Info] Number of data points in the train set: 2819555, number of used features: 10\n",
                  "[LightGBM] [Info] Start training from score 17.948049\n",
                  "LightGBM Regressor - R2: 0.0002, MSE: 3888492434.1465\n",
                  "XGBoost Regressor - R2: 0.0002, MSE: 3888524299.5376\n"
               ]
            }
         ],
         "source": [
            "\n",
            "import pandas as pd\n",
            "import numpy as np\n",
            "from sklearn.model_selection import train_test_split, cross_val_score\n",
            "from sklearn.linear_model import LinearRegression\n",
            "from sklearn.tree import DecisionTreeRegressor\n",
            "import lightgbm as lgb\n",
            "import xgboost as xgb\n",
            "from sklearn.metrics import r2_score, mean_squared_error\n",
            "\n",
            "\n",
            "\n",
            "# Drop datetime columns from the feature set\n",
            "X = X_train\n",
            "y = y_train_duration_in_minutes\n",
            "\n",
            "\n",
            "# LightGBM Regressor\n",
            "lgbm = lgb.LGBMRegressor(random_state=42)\n",
            "lgbm.fit(X_train, y_train_duration_in_minutes)\n",
            "y_pred_lgbm = lgbm.predict(X_test)\n",
            "r2_lgbm = r2_score(y_test_duration_in_minutes, y_pred_lgbm)\n",
            "mse_lgbm = mean_squared_error(y_test_duration_in_minutes, y_pred_lgbm)\n",
            "# Save the model\n",
            "#with open('lightgbm_regressor_model.pkl', 'wb') as file:\n",
            "  #pickle.dump(lgbm, file)\n",
            "\n",
            "# XGBoost Regressor\n",
            "xgbr = xgb.XGBRegressor(random_state=42)\n",
            "xgbr.fit(X_train, y_train_duration_in_minutes)\n",
            "y_pred_xgbr = xgbr.predict(X_test)\n",
            "r2_xgbr = r2_score(y_test_duration_in_minutes, y_pred_xgbr)\n",
            "mse_xgbr = mean_squared_error(y_test_duration_in_minutes, y_pred_xgbr)\n",
            "# Save the model\n",
            "with open('xgboost_time.pkl', 'wb') as file:\n",
            "    pickle.dump(xgbr, file)\n",
            "\n",
            "\n",
            "# Print the results\n",
            "print(f\"LightGBM Regressor - R2: {r2_lgbm:.4f}, MSE: {mse_lgbm:.4f}\")\n",
            "print(f\"XGBoost Regressor - R2: {r2_xgbr:.4f}, MSE: {mse_xgbr:.4f}\")\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 64,
         "metadata": {},
         "outputs": [],
         "source": [
            "X_train = pd.DataFrame(X_train)\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 65,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "[5, 0.5543892]\n",
                  "[4, 0.27518803]\n",
                  "[2, 0.08844095]\n",
                  "[9, 0.014992741]\n",
                  "[3, 0.01447094]\n",
                  "[0, 0.013425942]\n",
                  "[1, 0.012020561]\n",
                  "[10, 0.009763655]\n",
                  "[8, 0.008657143]\n",
                  "[7, 0.008650819]\n",
                  "[6, 0.0]\n",
                  "Lgbm\n"
               ]
            }
         ],
         "source": [
            "sorted_idx = np.argsort(xgbr.feature_importances_)[::-1]\n",
            "for index in sorted_idx:\n",
            "    print([X_train.columns[index], xgbr.feature_importances_[index]])\n",
            "print('Lgbm')"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Time"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 56,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.099423 seconds.\n",
                  "You can set `force_col_wise=true` to remove the overhead.\n",
                  "[LightGBM] [Info] Total Bins 1066\n",
                  "[LightGBM] [Info] Number of data points in the train set: 2819555, number of used features: 10\n",
                  "[LightGBM] [Info] Start training from score 17.948049\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "c:\\Users\\jaime\\anaconda3\\envs\\scraping1\\lib\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
                  "  warnings.warn(\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "[0]\tvalidation_0-rmse:38.39164\n",
                  "[1]\tvalidation_0-rmse:29.20703\n",
                  "[2]\tvalidation_0-rmse:23.38554\n",
                  "[3]\tvalidation_0-rmse:19.76192\n",
                  "[4]\tvalidation_0-rmse:17.73616\n",
                  "[5]\tvalidation_0-rmse:16.61646\n",
                  "[6]\tvalidation_0-rmse:15.75493\n",
                  "[7]\tvalidation_0-rmse:15.39691\n",
                  "[8]\tvalidation_0-rmse:15.21760\n",
                  "[9]\tvalidation_0-rmse:15.07250\n",
                  "[10]\tvalidation_0-rmse:14.94881\n",
                  "[11]\tvalidation_0-rmse:14.86652\n",
                  "[12]\tvalidation_0-rmse:14.81927\n",
                  "[13]\tvalidation_0-rmse:14.76033\n",
                  "[14]\tvalidation_0-rmse:14.75561\n",
                  "[15]\tvalidation_0-rmse:14.65077\n",
                  "[16]\tvalidation_0-rmse:14.65837\n",
                  "[17]\tvalidation_0-rmse:14.64342\n",
                  "[18]\tvalidation_0-rmse:14.63340\n",
                  "[19]\tvalidation_0-rmse:14.63064\n",
                  "[20]\tvalidation_0-rmse:14.65485\n",
                  "[21]\tvalidation_0-rmse:14.65534\n",
                  "[22]\tvalidation_0-rmse:14.58322\n",
                  "[23]\tvalidation_0-rmse:14.56618\n",
                  "[24]\tvalidation_0-rmse:14.53094\n",
                  "[25]\tvalidation_0-rmse:14.45408\n",
                  "[26]\tvalidation_0-rmse:14.44846\n",
                  "[27]\tvalidation_0-rmse:14.43801\n",
                  "[28]\tvalidation_0-rmse:14.48201\n",
                  "[29]\tvalidation_0-rmse:14.48844\n",
                  "[30]\tvalidation_0-rmse:14.47806\n",
                  "[31]\tvalidation_0-rmse:14.46487\n",
                  "[32]\tvalidation_0-rmse:14.47608\n",
                  "[33]\tvalidation_0-rmse:14.47480\n",
                  "[34]\tvalidation_0-rmse:14.48136\n",
                  "[35]\tvalidation_0-rmse:14.47788\n",
                  "[36]\tvalidation_0-rmse:14.21038\n",
                  "[37]\tvalidation_0-rmse:14.21053\n",
                  "[38]\tvalidation_0-rmse:14.22254\n",
                  "[39]\tvalidation_0-rmse:14.25110\n",
                  "[40]\tvalidation_0-rmse:14.24014\n",
                  "[41]\tvalidation_0-rmse:14.27935\n",
                  "[42]\tvalidation_0-rmse:14.26624\n",
                  "[43]\tvalidation_0-rmse:14.27496\n",
                  "[44]\tvalidation_0-rmse:14.25583\n",
                  "[45]\tvalidation_0-rmse:14.26233\n",
                  "[46]\tvalidation_0-rmse:14.27614\n",
                  "[47]\tvalidation_0-rmse:14.27203\n",
                  "[48]\tvalidation_0-rmse:14.27183\n",
                  "[49]\tvalidation_0-rmse:14.26110\n",
                  "[50]\tvalidation_0-rmse:14.26382\n",
                  "[51]\tvalidation_0-rmse:14.27453\n",
                  "[52]\tvalidation_0-rmse:14.29688\n",
                  "[53]\tvalidation_0-rmse:14.29786\n",
                  "[54]\tvalidation_0-rmse:14.30181\n",
                  "[55]\tvalidation_0-rmse:14.29509\n",
                  "[56]\tvalidation_0-rmse:14.29272\n",
                  "[57]\tvalidation_0-rmse:14.31139\n",
                  "[58]\tvalidation_0-rmse:14.32368\n",
                  "[59]\tvalidation_0-rmse:14.32183\n",
                  "[60]\tvalidation_0-rmse:14.32025\n",
                  "[61]\tvalidation_0-rmse:14.32025\n",
                  "[62]\tvalidation_0-rmse:14.32291\n",
                  "[63]\tvalidation_0-rmse:14.33318\n",
                  "[64]\tvalidation_0-rmse:14.33956\n",
                  "[65]\tvalidation_0-rmse:14.34503\n",
                  "[66]\tvalidation_0-rmse:14.34173\n",
                  "[67]\tvalidation_0-rmse:14.34787\n",
                  "[68]\tvalidation_0-rmse:14.36703\n",
                  "[69]\tvalidation_0-rmse:14.37047\n",
                  "[70]\tvalidation_0-rmse:14.36395\n",
                  "[71]\tvalidation_0-rmse:14.36825\n",
                  "[72]\tvalidation_0-rmse:14.36117\n",
                  "[73]\tvalidation_0-rmse:14.37396\n",
                  "[74]\tvalidation_0-rmse:14.30996\n",
                  "[75]\tvalidation_0-rmse:14.31342\n",
                  "[76]\tvalidation_0-rmse:14.33196\n",
                  "[77]\tvalidation_0-rmse:14.34218\n",
                  "[78]\tvalidation_0-rmse:14.33144\n",
                  "[79]\tvalidation_0-rmse:14.32901\n",
                  "[80]\tvalidation_0-rmse:14.32981\n",
                  "[81]\tvalidation_0-rmse:14.32930\n",
                  "[82]\tvalidation_0-rmse:14.31804\n",
                  "[83]\tvalidation_0-rmse:14.31682\n",
                  "[84]\tvalidation_0-rmse:14.31962\n",
                  "[85]\tvalidation_0-rmse:14.35263\n",
                  "[86]\tvalidation_0-rmse:14.36014\n",
                  "[87]\tvalidation_0-rmse:14.35299\n",
                  "[88]\tvalidation_0-rmse:14.35615\n",
                  "[89]\tvalidation_0-rmse:14.35443\n",
                  "[90]\tvalidation_0-rmse:14.36552\n",
                  "[91]\tvalidation_0-rmse:14.37956\n",
                  "[92]\tvalidation_0-rmse:14.41181\n",
                  "[93]\tvalidation_0-rmse:14.41482\n",
                  "[94]\tvalidation_0-rmse:14.41265\n",
                  "[95]\tvalidation_0-rmse:14.39994\n",
                  "[96]\tvalidation_0-rmse:14.36445\n",
                  "[97]\tvalidation_0-rmse:14.36329\n",
                  "[98]\tvalidation_0-rmse:14.36808\n",
                  "[99]\tvalidation_0-rmse:14.37046\n",
                  "LightGBM Regressor - R2: 0.0002, MSE: 3888492434.1465\n",
                  "XGBoost Regressor - R2: 0.0002, MSE: 3888524299.5376\n"
               ]
            }
         ],
         "source": [
            "import pandas as pd\n",
            "import numpy as np\n",
            "from sklearn.model_selection import train_test_split, cross_val_score\n",
            "from sklearn.linear_model import LinearRegression\n",
            "from sklearn.tree import DecisionTreeRegressor\n",
            "import lightgbm as lgb\n",
            "import xgboost as xgb\n",
            "from sklearn.metrics import r2_score, mean_squared_error\n",
            "\n",
            "\n",
            "\n",
            "# Drop datetime columns from the feature set\n",
            "X = X_train\n",
            "y = y_train_duration_in_minutes\n",
            "\n",
            "\n",
            "# LightGBM Regressor\n",
            "lgbm = lgb.LGBMRegressor(random_state=42)\n",
            "lgbm.fit(X, y, eval_set=[(X_val, y_val_duration_in_minutes)], eval_metric='rmse')\n",
            "y_pred_lgbm = lgbm.predict(X_test)\n",
            "r2_lgbm = r2_score(y_test_duration_in_minutes, y_pred_lgbm)\n",
            "mse_lgbm = mean_squared_error(y_test_duration_in_minutes, y_pred_lgbm)\n",
            "# Save the model\n",
            "with open('lightgbm_time.pkl', 'wb') as file:\n",
            "    pickle.dump(lgbm, file)\n",
            "\n",
            "# XGBoost Regressor\n",
            "xgbr = xgb.XGBRegressor(random_state=42)\n",
            "xgbr.fit(X, y, eval_set=[(X_val,y_val_duration_in_minutes)], eval_metric='rmse')\n",
            "y_pred_xgbr = xgbr.predict(X_test)\n",
            "r2_xgbr = r2_score(y_test_duration_in_minutes, y_pred_xgbr)\n",
            "mse_xgbr = mean_squared_error(y_test_duration_in_minutes, y_pred_xgbr)\n",
            "# Save the model\n",
            "with open('xgboost_time.pkl', 'wb') as file:\n",
            "    pickle.dump(xgbr, file)\n",
            "\n",
            "# Print the results\n",
            "print(f\"LightGBM Regressor - R2: {r2_lgbm:.4f}, MSE: {mse_lgbm:.4f}\")\n",
            "print(f\"XGBoost Regressor - R2: {r2_xgbr:.4f}, MSE: {mse_xgbr:.4f}\")\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 137,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "MAE: 8.499936202490034\n",
                  "MSE: 227.1152783615407\n",
                  "RMSE: 15.070344334537971\n",
                  "R2: 0.3392703528507055\n",
                  "_________________________:\n",
                  "MAE: 8.459752577545961\n",
                  "MSE: 204.6382722531288\n",
                  "RMSE: 14.305183405085334\n",
                  "R2: 0.35828908484859767\n"
               ]
            }
         ],
         "source": [
            "from sklearn.linear_model import LinearRegression\n",
            "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
            "from src.save_model import save_total_trip_model,save_duration_trip_model\n",
            "import math\n",
            "\n",
            "# Create a linear regression model\n",
            "model = LinearRegression()\n",
            "\n",
            "# Fit the model\n",
            "model.fit(X_train, y_train_total_amount)\n",
            "\n",
            "save_total_trip_model(model)\n",
            "# Predict using the model\n",
            "\n",
            "y_pred_train = model.predict(X_train)\n",
            "print('MAE:', mean_absolute_error(y_train_total_amount, y_pred_train))\n",
            "print('MSE:', mean_squared_error(y_train_total_amount, y_pred_train))\n",
            "print('RMSE:', math.sqrt(mean_squared_error(y_train_total_amount, y_pred_train)))\n",
            "print('R2:', r2_score(y_train_total_amount, y_pred_train))\n",
            "print('_________________________:')\n",
            "\n",
            "y_pred_val = model.predict(X_val)\n",
            "print('MAE:', mean_absolute_error(y_val_total_amount, y_pred_val))\n",
            "print('MSE:', mean_squared_error(y_val_total_amount, y_pred_val))\n",
            "print('RMSE:', math.sqrt(mean_squared_error(y_val_total_amount, y_pred_val)))\n",
            "print('R2:', r2_score(y_val_total_amount, y_pred_val))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### Trip duration prediction"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 138,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "(2767016, 11)\n",
                  "(2767016,)\n",
                  "MAE: 10.507362989449026\n",
                  "MSE: 2689.339306865035\n",
                  "RMSE: 51.85884019976763\n",
                  "R2: 0.017765573487283692\n",
                  "_________________________:\n",
                  "MAE: 10.524926375876877\n",
                  "MSE: 2739.279361595603\n",
                  "RMSE: 52.33812531602181\n",
                  "R2: 0.01666234906141406\n"
               ]
            }
         ],
         "source": [
            "# Create a linear regression model\n",
            "model_duration = LinearRegression()\n",
            "\n",
            "print(X_train.shape)\n",
            "print(y_train_duration_in_minutes.shape)\n",
            "# Fit the model\n",
            "model_duration.fit(X_train, y_train_duration_in_minutes)\n",
            "\n",
            "save_duration_trip_model(model_duration)\n",
            "# Predict using the model\n",
            "\n",
            "y_pred_train = model_duration.predict(X_train)\n",
            "print('MAE:', mean_absolute_error(y_train_duration_in_minutes, y_pred_train))\n",
            "print('MSE:', mean_squared_error(y_train_duration_in_minutes, y_pred_train))\n",
            "print('RMSE:', math.sqrt(mean_squared_error(y_train_duration_in_minutes, y_pred_train)))\n",
            "print('R2:', r2_score(y_train_duration_in_minutes, y_pred_train))\n",
            "print('_________________________:')\n",
            "\n",
            "y_pred_val = model_duration.predict(X_val)\n",
            "print('MAE:', mean_absolute_error(y_val_duration_in_minutes, y_pred_val))\n",
            "print('MSE:', mean_squared_error(y_val_duration_in_minutes, y_pred_val))\n",
            "print('RMSE:', math.sqrt(mean_squared_error(y_val_duration_in_minutes, y_pred_val)))\n",
            "print('R2:', r2_score(y_val_duration_in_minutes, y_pred_val))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### DecisionTreeRegressor"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 139,
         "metadata": {},
         "outputs": [],
         "source": [
            "from sklearn.tree import DecisionTreeRegressor\n",
            "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
            "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
            "import math"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 140,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "MAE: 5.927281148257893\n",
                  "MSE: 128.48125407285585\n",
                  "RMSE: 11.334957171196363\n",
                  "R2: 0.6262190096532394\n",
                  "val:\n",
                  "MAE: 5.91380714453071\n",
                  "MSE: 108.65590724153505\n",
                  "RMSE: 10.423814428582995\n",
                  "R2: 0.6592735029236191\n"
               ]
            }
         ],
         "source": [
            "tree = DecisionTreeRegressor(max_depth=10)\n",
            "tree.fit(X_train, y_train_total_amount)\n",
            "\n",
            "# Evaluate the model\n",
            "y_pred_train_DTR = tree.predict(X_train)\n",
            "\n",
            "\n",
            "\n",
            "print('MAE:', mean_absolute_error(y_train_total_amount, y_pred_train_DTR))\n",
            "print('MSE:', mean_squared_error(y_train_total_amount, y_pred_train_DTR))\n",
            "print('RMSE:', math.sqrt(mean_squared_error(y_train_total_amount, y_pred_train_DTR)))\n",
            "print('R2:', r2_score(y_train_total_amount, y_pred_train_DTR))\n",
            "\n",
            "y_pred_val_DTR = tree.predict(X_val)\n",
            "\n",
            "print('val:')\n",
            "\n",
            "print('MAE:', mean_absolute_error(y_val_total_amount, y_pred_val_DTR))\n",
            "print('MSE:', mean_squared_error(y_val_total_amount, y_pred_val_DTR))\n",
            "print('RMSE:', math.sqrt(mean_squared_error(y_val_total_amount, y_pred_val_DTR)))\n",
            "print('R2:', r2_score(y_val_total_amount, y_pred_val_DTR))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### XGBRegressor"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 143,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "__version__ 2.0.3\n",
                  "MAE: 8.499936202490034\n",
                  "MSE: 227.1152783615407\n",
                  "RMSE: 15.070344334537971\n",
                  "R2: 0.34\n",
                  "Val:\n",
                  "MAE: 8.459752577545961\n",
                  "MSE: 204.6382722531288\n",
                  "RMSE: 14.305183405085334\n",
                  "R2: 0.36\n"
               ]
            }
         ],
         "source": [
            "import xgboost as xgb\n",
            "print('__version__',xgb.__version__)\n",
            "from sklearn.datasets import make_regression\n",
            "#XGBRegressor\n",
            "model_xgb = xgb.XGBRegressor(objective='reg:squarederror', n_jobs=1, random_state=42,\n",
            "                               n_estimators=500, max_depth=5, learning_rate=00.1, \n",
            "                               subsample=0.8, colsample_bytree=0.8)\n",
            "\n",
            "# Fit the model\n",
            "model_xgb.fit(X_train, y_train_total_amount)\n",
            "\n",
            "y_pred_train_xgb = model.predict(X_train)\n",
            "\n",
            "print('MAE:', mean_absolute_error(y_train_total_amount, y_pred_train_xgb))\n",
            "print(\"MSE:\", mean_squared_error(y_train_total_amount, y_pred_train_xgb))\n",
            "print('RMSE:', math.sqrt(mean_squared_error(y_train_total_amount, y_pred_train_xgb)))\n",
            "r2 = r2_score(y_train_total_amount, y_pred_train_xgb)\n",
            "print(f\"R2: {r2_score(y_train_total_amount, y_pred_train_xgb):.2f}\")\n",
            "\n",
            "# Predicting the Test set results\n",
            "y_pred_val_xgb = model.predict(X_val)\n",
            "\n",
            "print(\"Val:\")\n",
            "print('MAE:', mean_absolute_error(y_val_total_amount, y_pred_val_xgb))\n",
            "print(\"MSE:\", mean_squared_error(y_val_total_amount, y_pred_val_xgb))\n",
            "print('RMSE:', math.sqrt(mean_squared_error(y_val_total_amount, y_pred_val_xgb)))\n",
            "print(f\"R2: {r2_score(y_val_total_amount, y_pred_val_xgb):.2f}\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### Random Forest Regressor"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 150,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "MAE: 7.254991895333542\n",
                  "MSE: 172.27699229871806\n",
                  "RMSE: 13.125433032807644\n",
                  "R2: 0.50\n",
                  "Val:\n",
                  "MAE: 8.459752577545961\n",
                  "MSE: 204.6382722531288\n",
                  "RMSE: 14.305183405085334\n",
                  "R2: 0.36\n"
               ]
            }
         ],
         "source": [
            "rf_reg = RandomForestRegressor(n_estimators=6, max_depth=5, random_state=42, n_jobs=1)\n",
            "rf_reg.fit(X_train, y_train_total_amount)\n",
            "\n",
            "# Evaluate the model\n",
            "y_pred_train_RFR = rf_reg.predict(X_train)\n",
            "\n",
            "print('MAE:', mean_absolute_error(y_train_total_amount, y_pred_train_RFR))\n",
            "print(\"MSE:\", mean_squared_error(y_train_total_amount, y_pred_train_RFR))\n",
            "print('RMSE:', math.sqrt(mean_squared_error(y_train_total_amount, y_pred_train_RFR)))\n",
            "r2 = r2_score(y_train_total_amount, y_pred_train_RFR)\n",
            "print(f\"R2: {r2_score(y_train_total_amount, y_pred_train_RFR):.2f}\")\n",
            "\n",
            "# Predicting the Test set results\n",
            "y_pred_val_RFR = model.predict(X_val)\n",
            "\n",
            "print(\"Val:\")\n",
            "print('MAE:', mean_absolute_error(y_val_total_amount, y_pred_val_RFR))\n",
            "print(\"MSE:\", mean_squared_error(y_val_total_amount, y_pred_val_RFR))\n",
            "print('RMSE:', math.sqrt(mean_squared_error(y_val_total_amount, y_pred_val_RFR)))\n",
            "print(f\"R2: {r2_score(y_val_total_amount, y_pred_val_RFR):.2f}\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Advanced cross validation\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 153,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "MSE: 115.78741919896211 Std: 49.406062188298016\n"
               ]
            }
         ],
         "source": [
            "from sklearn.model_selection import cross_val_score, KFold\n",
            "X, y = X_train, y_train_total_amount\n",
            "# Create a random forest regression model\n",
            "model = RandomForestRegressor(n_estimators=10)\n",
            "\n",
            "# Configure the cross-validation procedure\n",
            "cv = KFold(n_splits=10, shuffle=True)\n",
            "\n",
            "# Evaluate the model using the cross-validation procedure\n",
            "scores = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=cv)\n",
            "\n",
            "# The scores are negative, which is how scikit-learn shows them for MSE (want to maximize negative MSE)\n",
            "mse_scores = -scores\n",
            "\n",
            "# Mean and standard deviation of MSE across all folds\n",
            "print(\"MSE:\", mse_scores.mean(), \"Std:\", mse_scores.std())"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": 154,
         "metadata": {},
         "outputs": [],
         "source": [
            "from sklearn.ensemble import StackingRegressor\n",
            "import xgboost as xgb\n",
            "# Base models\n",
            "model1 = RandomForestRegressor(random_state=42)\n",
            "model2 = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, seed=123)\n",
            "model3 = RandomForestRegressor(n_estimators=100)\n",
            "\n",
            "# Defining the meta model, using a regressor \n",
            "meta_model = RandomForestRegressor(random_state=42)\n",
            "\n",
            "# Create Stacking model\n",
            "stacking_model = StackingRegressor(\n",
            "    estimators=[('rf1', model1), ('xgb', model2), ('rf2', model3)],\n",
            "    final_estimator=meta_model,\n",
            "    cv=5\n",
            ")\n",
            "\n",
            "# Training the model\n",
            "stacking_model.fit(X_train, y_train_total_amount)\n",
            "\n",
            "# Predictions\n",
            "y_pred = stacking_model.predict(X_test)\n",
            "\n",
            "# Evaluation metrics\n",
            "# Calculate MSE\n",
            "mse = mean_squared_error(y_test_total_amount, y_pred)\n",
            "print(f\"Mean Squared Error: {mse:.2f}\")\n",
            "\n",
            "# Calculate R-squared\n",
            "r2 = r2_score(y_test, y_pred)\n",
            "print(f\"R-squared: {r2:.2f}\")"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "finalprojectenv",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.13"
      },
      "vscode": {
         "interpreter": {
            "hash": "5efa683b5b1ae7e8e11b6b316072de2b1afb735b3660bedb7c7a61c7b9dc51db"
         }
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
